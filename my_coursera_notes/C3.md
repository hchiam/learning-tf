# Natural Language Processing in TensorFlow

- course: https://www.coursera.org/learn/natural-language-processing-tensorflow

- slides: https://community.deeplearning.ai/t/tf1-course-1-lecture-notes/124222

- companion repo: https://github.com/https-deeplearning-ai/tensorflow-1-public/tree/main/C3

- discussion forum: https://community.deeplearning.ai/c/tf1/tf1-course-3/81

```py
import tensorflow as tf
from tf import keras
from tf.keras.preprocessing.text import Tokenizer
from tf.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(
  num_words=100, # use top 100 most-common words to tokenize for tons of data
  oov_token='<OOV>', # mark not-yet-seen words as OOV = Out Of Vocabulary
)

sentences = ['I love my dog', 'I love my cat']
tokenizer.fit_on_texts(sentences)

word_index = tokenizer.word_index # dictionary key-value pairs
print(word_index) # {'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}

sequences = tokenizer.texts_to_sequences(sentences)
print(sequences) # [[1,2,3,4], [1,2,3,5]]

padded = pad_sequences( # add 0s to make inputs of uniform size
  sequences,
  padding='post', # use 'post' to add padding to end of sentence
  maxlen=5, # max number of words to include in encoding, and then
  truncating='post' # truncate from end of sentence if there too many words in sentence
)
```
