# Convolutional Neural Networks in TensorFlow

https://www.coursera.org/learn/convolutional-neural-networks-tensorflow

Discussion forum: https://community.deeplearning.ai/c/tf1/tf1-course-2/80

- multiple layers of convolution be thought of as distilling information contributing to determining an image class

- data cleaning: handle inconsistent image sizes, other things in the images, converting to numbers in a normalized 0-1 range, etc.

  - example code/colab: https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W1/ungraded_lab/C2_W1_Lab_1_cats_vs_dogs.ipynb

    - remember: for a 2-class (binary) classification output (0% - 100% probability of being class A instead of class B), you can use `activation='sigmoid'` for the output layer, and `loss='binary_crossentropy'`

    - convert colour ranges from 0-255 to 0-1 using `data_generator = keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.)` (for training - for model usage, you might be able to just do something like `x = tensorflow.keras.utils.img_to_array(img) / 255`)

    - `training_data_generator = data_generator.flow_from_directory(dir,batch_size,class_mode='binary',target_size=(150,150))`

    - this colab also gives example code for visualizing each layer to see intermediate feature representations (by using the original model to create another model that is able to provide us the multiple outputs (per-layer outputs))
