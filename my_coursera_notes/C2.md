# Convolutional Neural Networks in TensorFlow

https://www.coursera.org/learn/convolutional-neural-networks-tensorflow

Discussion forum: https://community.deeplearning.ai/c/tf1/tf1-course-2/80

- multiple layers of convolution be thought of as distilling information contributing to determining an image class

- data cleaning: handle inconsistent image sizes, other things in the images, converting to numbers in a normalized 0-1 range, etc.

  - example code/colab: https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W1/ungraded_lab/C2_W1_Lab_1_cats_vs_dogs.ipynb and https://colab.research.google.com/drive/1brqWrx-6qf9Pg3cnxy0uygwV5kjELPZF?usp=sharing

    - remember: for a 2-class (binary) classification output (0% - 100% probability of being class A instead of class B), you can use `activation='sigmoid'` for the output layer, and `loss='binary_crossentropy'`

    - `os.path.join` and `os.makedirs`

    - convert colour ranges from 0-255 to 0-1 using `data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.)` (for training - for model usage, you might be able to just do something like `x = tensorflow.keras.utils.img_to_array(img) / 255`)

    - `training_data_generator = data_generator.flow_from_directory(dir,batch_size,class_mode='binary',target_size=(150,150))`

    - this colab also gives example code for visualizing each layer to see intermediate feature representations (by using the original model to create another model that is able to provide us the multiple outputs (per-layer outputs)) - note `display_grid`

    - this colab also has code for tracking learning history, which can be used to check for overfitting (training versus validation loss) - consider stopping after 2 epochs of training? or do something else?

- data generation/augmentation: e.g. "image augmentation", that is, to generate images that are rotated, skewed, etc. so you can try to cover more possible cases when you have not enough data

  - it's actually better to let tensorflow do this on the fly (instead of using up storage faster with making actual copies of images, and to start with unchanged data)
