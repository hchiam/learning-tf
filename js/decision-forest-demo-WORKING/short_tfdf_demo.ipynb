{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "combining\n",
        "\n",
        "https://github.com/hchiam/decision-forests#usage-example\n",
        "\n",
        "and\n",
        "\n",
        "https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\n",
        "https://colab.research.google.com/drive/1y5JQxgP2eQKPno5rhWEP-pEiGgy1NByO#scrollTo=BRKLWIWNuOZ1"
      ],
      "metadata": {
        "id": "t1FPDt0Yiscb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hidden code cell below lets you limit the output height in colab with\n",
        "\n",
        "`%set_cell_height 100`"
      ],
      "metadata": {
        "id": "3470oiffjH4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import display as ipy_display\n",
        "\n",
        "# Some of the model training logs can cover the full\n",
        "# screen if not compressed to a smaller viewport.\n",
        "# This magic allows setting a max height for a cell.\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  ipy_display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MpmokH0yjD8y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# silence output:\n",
        "%%capture\n",
        "\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install 'tensorflowjs>=4.4.0'\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflowjs as tfjs\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "Tb-I4ROQi1AW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell is just setup to get the CSV data into `train_ds` and `test_ds` and set up `label`:"
      ],
      "metadata": {
        "id": "n1gC2mJ0jjYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"/tmp/penguins.csv\")\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)\n",
        "\n",
        "# Split the dataset into a training and a testing dataset.\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "label='species'\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5UrGkYVjWFX",
        "outputId": "7a01948c-1d0b-4871-ab6e-ead0012ba0a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250 examples in training, 94 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "QSTUY1LxicZy",
        "outputId": "4c728b0d-6b5f-4f23-976e-5d434310e5b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp9cc06pxn as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7fbb5bcd0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.236018. Found 250 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.084901\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fbb555072e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7fbb55428790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (7):\n",
            "\tbill_depth_mm\n",
            "\tbill_length_mm\n",
            "\tbody_mass_g\n",
            "\tflipper_length_mm\n",
            "\tisland\n",
            "\tsex\n",
            "\tyear\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"bill_length_mm\"  0.476350 ################\n",
            "    2. \"flipper_length_mm\"  0.406154 ###########\n",
            "    3.     \"bill_depth_mm\"  0.332945 #####\n",
            "    4.            \"island\"  0.309721 ####\n",
            "    5.       \"body_mass_g\"  0.283886 ##\n",
            "    6.               \"sex\"  0.252181 \n",
            "    7.              \"year\"  0.251575 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.    \"bill_length_mm\" 124.000000 ################\n",
            "    2. \"flipper_length_mm\" 122.000000 ###############\n",
            "    3.     \"bill_depth_mm\" 42.000000 #####\n",
            "    4.       \"body_mass_g\"  8.000000 \n",
            "    5.            \"island\"  4.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.    \"bill_length_mm\" 637.000000 ################\n",
            "    2.     \"bill_depth_mm\" 388.000000 #########\n",
            "    3. \"flipper_length_mm\" 304.000000 #######\n",
            "    4.            \"island\" 237.000000 #####\n",
            "    5.       \"body_mass_g\" 217.000000 #####\n",
            "    6.               \"sex\" 18.000000 \n",
            "    7.              \"year\" 10.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"bill_length_mm\" 31547.338519 ################\n",
            "    2. \"flipper_length_mm\" 19896.055701 ##########\n",
            "    3.            \"island\" 10533.714590 #####\n",
            "    4.     \"bill_depth_mm\" 9462.816915 ####\n",
            "    5.       \"body_mass_g\" 3801.944399 #\n",
            "    6.               \"sex\" 118.162831 \n",
            "    7.              \"year\" 21.759911 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.972 logloss:0.081762\n",
            "Number of trees: 300\n",
            "Total number of nodes: 3922\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 13.0733 StdDev: 3.20956\n",
            "Min: 7 Max: 29 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  7,  8)  3   1.00%   1.00%\n",
            "[  8,  9)  0   0.00%   1.00%\n",
            "[  9, 10) 40  13.33%  14.33% ####\n",
            "[ 10, 11)  0   0.00%  14.33%\n",
            "[ 11, 12) 73  24.33%  38.67% ########\n",
            "[ 12, 13)  0   0.00%  38.67%\n",
            "[ 13, 15) 94  31.33%  70.00% ##########\n",
            "[ 15, 16) 47  15.67%  85.67% #####\n",
            "[ 16, 17)  0   0.00%  85.67%\n",
            "[ 17, 18) 27   9.00%  94.67% ###\n",
            "[ 18, 19)  0   0.00%  94.67%\n",
            "[ 19, 20)  3   1.00%  95.67%\n",
            "[ 20, 21)  0   0.00%  95.67%\n",
            "[ 21, 23)  9   3.00%  98.67% #\n",
            "[ 23, 24)  1   0.33%  99.00%\n",
            "[ 24, 25)  0   0.00%  99.00%\n",
            "[ 25, 26)  0   0.00%  99.00%\n",
            "[ 26, 27)  0   0.00%  99.00%\n",
            "[ 27, 28)  2   0.67%  99.67%\n",
            "[ 28, 29]  1   0.33% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 2111 Average: 3.081 StdDev: 0.956453\n",
            "Min: 1 Max: 8 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)   8   0.38%   0.38%\n",
            "[ 2, 3) 605  28.66%  29.04% #######\n",
            "[ 3, 4) 905  42.87%  71.91% ##########\n",
            "[ 4, 5) 437  20.70%  92.61% #####\n",
            "[ 5, 6) 125   5.92%  98.53% #\n",
            "[ 6, 7)  23   1.09%  99.62%\n",
            "[ 7, 8)   4   0.19%  99.81%\n",
            "[ 8, 8]   4   0.19% 100.00%\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 2111 Average: 35.5282 StdDev: 34.7116\n",
            "Min: 5 Max: 116 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  10) 939  44.48%  44.48% ##########\n",
            "[  10,  16)  98   4.64%  49.12% #\n",
            "[  16,  21)  64   3.03%  52.16% #\n",
            "[  21,  27)  53   2.51%  54.67% #\n",
            "[  27,  33)  58   2.75%  57.41% #\n",
            "[  33,  38)  84   3.98%  61.39% #\n",
            "[  38,  44)  99   4.69%  66.08% #\n",
            "[  44,  49)  69   3.27%  69.35% #\n",
            "[  49,  55)  55   2.61%  71.96% #\n",
            "[  55,  61)  24   1.14%  73.09%\n",
            "[  61,  66)  21   0.99%  74.09%\n",
            "[  66,  72)  35   1.66%  75.75%\n",
            "[  72,  77)  46   2.18%  77.93%\n",
            "[  77,  83)  80   3.79%  81.71% #\n",
            "[  83,  89) 120   5.68%  87.40% #\n",
            "[  89,  94)  94   4.45%  91.85% #\n",
            "[  94, 100)  80   3.79%  95.64% #\n",
            "[ 100, 105)  47   2.23%  97.87% #\n",
            "[ 105, 111)  34   1.61%  99.48%\n",
            "[ 111, 116]  11   0.52% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t637 : bill_length_mm [NUMERICAL]\n",
            "\t388 : bill_depth_mm [NUMERICAL]\n",
            "\t304 : flipper_length_mm [NUMERICAL]\n",
            "\t237 : island [CATEGORICAL]\n",
            "\t217 : body_mass_g [NUMERICAL]\n",
            "\t18 : sex [CATEGORICAL]\n",
            "\t10 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t124 : bill_length_mm [NUMERICAL]\n",
            "\t122 : flipper_length_mm [NUMERICAL]\n",
            "\t42 : bill_depth_mm [NUMERICAL]\n",
            "\t8 : body_mass_g [NUMERICAL]\n",
            "\t4 : island [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t273 : bill_length_mm [NUMERICAL]\n",
            "\t195 : flipper_length_mm [NUMERICAL]\n",
            "\t187 : bill_depth_mm [NUMERICAL]\n",
            "\t154 : island [CATEGORICAL]\n",
            "\t83 : body_mass_g [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t492 : bill_length_mm [NUMERICAL]\n",
            "\t320 : bill_depth_mm [NUMERICAL]\n",
            "\t276 : flipper_length_mm [NUMERICAL]\n",
            "\t207 : island [CATEGORICAL]\n",
            "\t165 : body_mass_g [NUMERICAL]\n",
            "\t11 : sex [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t594 : bill_length_mm [NUMERICAL]\n",
            "\t373 : bill_depth_mm [NUMERICAL]\n",
            "\t296 : flipper_length_mm [NUMERICAL]\n",
            "\t234 : island [CATEGORICAL]\n",
            "\t206 : body_mass_g [NUMERICAL]\n",
            "\t16 : sex [CATEGORICAL]\n",
            "\t5 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t633 : bill_length_mm [NUMERICAL]\n",
            "\t387 : bill_depth_mm [NUMERICAL]\n",
            "\t304 : flipper_length_mm [NUMERICAL]\n",
            "\t237 : island [CATEGORICAL]\n",
            "\t217 : body_mass_g [NUMERICAL]\n",
            "\t18 : sex [CATEGORICAL]\n",
            "\t10 : year [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t1556 : HigherCondition\n",
            "\t255 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t296 : HigherCondition\n",
            "\t4 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t738 : HigherCondition\n",
            "\t154 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1253 : HigherCondition\n",
            "\t218 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t1474 : HigherCondition\n",
            "\t250 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t1551 : HigherCondition\n",
            "\t255 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.947917 logloss:1.87727\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.964 logloss:0.350565\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.968 logloss:0.222003\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.96 logloss:0.217322\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.96 logloss:0.0870238\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.96 logloss:0.0846563\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.964 logloss:0.0848987\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.968 logloss:0.0882875\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.968 logloss:0.0858539\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.968 logloss:0.087091\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.968 logloss:0.0861036\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.968 logloss:0.0854867\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.968 logloss:0.0840652\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.968 logloss:0.0846687\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.968 logloss:0.0852916\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.968 logloss:0.0837553\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.972 logloss:0.0824821\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.972 logloss:0.0827575\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.972 logloss:0.0827899\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.972 logloss:0.081924\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.972 logloss:0.0826341\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.972 logloss:0.0820786\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.972 logloss:0.0823061\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.972 logloss:0.0828726\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.972 logloss:0.0822572\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.972 logloss:0.0828086\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.972 logloss:0.0822961\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.972 logloss:0.0820119\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.972 logloss:0.0814775\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.972 logloss:0.0814725\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.972 logloss:0.081762\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7fbb5542a4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "# # Load the dataset in a Pandas dataframe.\n",
        "# train_df = pd.read_csv(\"project/train.csv\")\n",
        "# test_df = pd.read_csv(\"project/test.csv\")\n",
        "\n",
        "# # Convert the dataset into a TensorFlow dataset.\n",
        "# train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"my_label\")\n",
        "# test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=\"my_label\")\n",
        "\n",
        "# Train the model\n",
        "model = tfdf.keras.RandomForestModel()\n",
        "model.fit(train_ds)\n",
        "\n",
        "# Look at the model.\n",
        "model.summary()\n",
        "\n",
        "# Evaluate the model.\n",
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so it's easier to tell that the colab actually saved a new project/model\n",
        "!rm -rf project/model"
      ],
      "metadata": {
        "id": "_9TxctiJldAw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Export to a TensorFlow SavedModel.\n",
        "# # Note: the model is compatible with Yggdrasil Decision Forests.\n",
        "# model.save(\"project/model\")"
      ],
      "metadata": {
        "id": "zDWlVQgBlMC3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in the SavedModel format\n",
        "tf.saved_model.save(model, \"./saved_model\")\n",
        "\n",
        "# Convert the SavedModel to TensorFlow.js and save as a zip file\n",
        "tfjs.converters.tf_saved_model_conversion_v2.convert_tf_saved_model(\"./saved_model\", \"./tfjs_model\")\n",
        "\n",
        "# Download the converted TFJS model\n",
        "!zip -r tfjs_model.zip tfjs_model/\n",
        "files.download(\"tfjs_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "Ey1kJ37BmUFP",
        "outputId": "dd5dc21b-791b-44fe-fd5f-179f1df4c5c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Issue encountered when serializing table_initializer.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'NoneType' object has no attribute 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight StatefulPartitionedCall/random_forest_model_4/StatefulPartitionedCall/RaggedConstant/Const with shape (1,) and dtype int64 was auto converted to the type int32\n",
            "weight StatefulPartitionedCall/random_forest_model_4/StatefulPartitionedCall/RaggedConstant/Const_1 with shape (1,) and dtype int64 was auto converted to the type int32\n",
            "  adding: tfjs_model/ (stored 0%)\n",
            "  adding: tfjs_model/group1-shard1of1.bin (deflated 36%)\n",
            "  adding: tfjs_model/model.json (deflated 91%)\n",
            "  adding: tfjs_model/assets.zip (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3c7f21d4-058f-42d2-99dc-b123f2f4d9ef\", \"tfjs_model.zip\", 304501)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_penguin = pd.DataFrame({\n",
        "    'island': tf.constant([\"Torgersen\"]),\n",
        "    'bill_length_mm': tf.constant([39.1]),\n",
        "    'bill_depth_mm': tf.constant([17.3]),\n",
        "    'flipper_length_mm': tf.constant([3.1]),\n",
        "    'body_mass_g': tf.constant([1000.0]),\n",
        "    'sex': tf.constant([\"Female\"]),\n",
        "    'year': tf.constant([2007], dtype=tf.int32),\n",
        "    'label': [0],\n",
        "})\n",
        "\n",
        "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(example_penguin, label=\"label\")\n",
        "\n",
        "for features, label in tf_dataset:\n",
        "  print(\"Features:\",features)\n",
        "  print(\"label:\", label)\n",
        "\n",
        "predictions = model.predict(tf_dataset, verbose=0)\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOekXadIoUfH",
        "outputId": "6137698f-c111-4939-cd9f-3084e1d875b4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: {'island': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Torgersen'], dtype=object)>, 'bill_length_mm': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([39.1], dtype=float32)>, 'bill_depth_mm': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([17.3], dtype=float32)>, 'flipper_length_mm': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.1], dtype=float32)>, 'body_mass_g': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>, 'sex': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Female'], dtype=object)>, 'year': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([2007], dtype=int32)>}\n",
            "label: tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "[[0.9933325  0.00666667 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = tf.math.argmax(predictions, axis=1).numpy()[0]\n",
        "print(f'Predicted index: {index}')\n",
        "labelClasses = [\"Adelie\", \"Gentoo\", \"Chinstrap\"]\n",
        "print(f'Predicted class: {labelClasses[index]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzpIZY6lsYUq",
        "outputId": "287df0bd-4b04-4c57-b789-c8fbbcd0ad31"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted index: 0\n",
            "Predicted class: Adelie\n"
          ]
        }
      ]
    }
  ]
}